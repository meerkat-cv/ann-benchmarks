# -*- coding: utf-8 ; org-export-babel-evaluate: t; org-confirm-babel-evaluate: nil; org-image-actual-width: 600;-*-
# -*- mode: org -*-
#+AUTHOR: Julio Toss
#+EMAIL: julio@meerkat.com.br
#+STARTUP: indent 
#+STARTUP: logdrawer hideblocks
#+OPTIONS: html-postamble:nil f:nil broken-links:mark H:5 toc:nil todo:nil ^:{}
#+PROPERTY: header-args :cache no :eval never-export
#+SEQ_TODO: TODO INPROGRESS(i) WAITING(@) | DONE NOTE DEFERRED(@) CANCELED(@)

* Content                                                               :TOC:
- [[#dataset---vgg-512-euclidean][Dataset - vgg-512-euclidean]]
- [[#evaluation-methodology][Evaluation methodology]]
  - [[#performance-metrics][Performance Metrics]]
  - [[#quality-metrics][Quality Metrics]]
- [[#results][Results]]
  - [[#query-time-vs-accuracy-rank1][Query Time vs accuracy-Rank@1]]
  - [[#query-time-vs-accuracy-rank10][Query Time vs accuracy-Rank@10]]
  - [[#index-build-time-vs-accuracy-rank1][Index Build Time vs accuracy-Rank@1]]
  - [[#index-size-vs-accuracy-rank1][Index Size vs accuracy-Rank@1]]

* DONE Dataset - vgg-512-euclidean

Dataset from face images : https://www.robots.ox.ac.uk/~vgg/data/vgg_face2/
Face descriptors (feature vectors) were extracted with frapi's method ( arcFace )

#+begin_src python :results output table :exports results :eval never
import numpy as np
import h5py

filename = "../data/vgg-512-euclidean.hdf5"
dataset = h5py.File(filename, "r")

train = set(dataset['train_lbl'])
test = set(dataset['test_lbl'])
diff = (test - train) 

print("Vectors type:", dataset['train'].dtype)
print("Train Vectors:", dataset['train'].shape)
print("Test Vectors:", dataset['test'].shape)

print("Train Labels:", len(train))
print("Test Labels:", len(test))

print("Untrained Labels: ", len(diff))

#+end_src

#+RESULTS:
: Vectors type: float64
: Train Vectors: (2701775, 512)
: Test Vectors: (10000, 512)
: Train Labels: 8631
: Test Labels: 5748
: Untrained Labels:  0

* Evaluation methodology 

For each algorithm configuration ( algorithm + parameters ):
- we build the indexing datastructure one time.
- we perform two test /runs/. In each /run/ the full /test/ dataset is queried over the computed index.
- each query is executed individually ( no batch queries ).

Resource limits:
Each test configuration is executed in a docker container. 
Containers resources where limited to 1 CPU, unlimited memory and run timeout of 5 hours.


** Performance Metrics
*** Index
- Index build time: we measure the seconds to run the method's =fit= function.
- Index memory usage: we compute the difference between the Resident Set Size , before and after the fit function.

Sample snippet: 
#+begin_src sh :results output :exports both
t0 = time.time()
memory_usage_before = algo.get_memory_usage()
algo.fit(X_train)
build_time = time.time() - t0
index_size = algo.get_memory_usage() - memory_usage_before
#+end_src

*** Query Time ( Latency )

In each test run, we measure seconds (wall time) for each query individually. 
All queries' times in a single run are added up to compute the average query time.

We perform two test /runs/ and take the best average time, which is reported in our results.

Each individual query time are save to =.hdf5= files in case we need them for extra analysis.

** Quality Metrics

The output of a knn-query is a list of neighbor's ids in the /Train/ dataset.

/Note:/ all the queries were executed on a *10-Nearest-Neighbors* index, so the response will always be a list of 10 candidates ordered by distance ( from smallest to largest ) 

From the list of candidates ids we generate a list candidate labels and compute the first position where the query label appears in the candidate list ( aka rank).

Rank computation:
#+begin_src python :results output :exports both
if query_label in neighbor_labels:
    rank_q = neighbor_labels.index( query_label )
else:
    rank_q = float(inf)
#+end_src

We computed two rank based accuracy :

- Accuracy at Rank@1 :: =( queries with rank < 1 ) / num_queries=

- Accuracy at Rank@10 :: =( queries with rank < 10) / num_queries=


* Algorithms                                                       :noexport:
** Selected algorithm 
Faiss
HNSW

* Results

#+begin_src sh :results none :exports both 
# To export all the metrics to a csv.
cd ../
python3 export_to_csv.py --dataset vgg-512-euclidean
#+end_src

Raw results are available here : [[../results/vgg-512-euclidean.csv]]

#+begin_src R :results output :exports none :session 
options(crayon.enabled = FALSE)
options(dplyr.width=Inf)

library(tidyverse)
df = read_delim("../results/vgg-512-euclidean.csv", delim=',', trim_ws = TRUE )
head(df)
#+end_src

#+RESULTS:
#+begin_example
── Attaching packages ─────────────────────────────────────── tidyverse 1.2.1 ──
✔ ggplot2 3.3.0     ✔ purrr   0.3.4
✔ tibble  2.1.3     ✔ dplyr   0.8.5
✔ tidyr   1.0.3     ✔ stringr 1.4.0
✔ readr   1.3.1     ✔ forcats 0.4.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
Parsed with column specification:
cols(
  dataset = col_character(),
  K = col_double(),
  distance = col_character(),
  algorithm = col_character(),
  parameters = col_character(),
  `k-nn` = col_double(),
  `accuracy-R@1` = col_double(),
  `accuracy-R@10` = col_double(),
  qps = col_double(),
  queryTime = col_double(),
  build = col_double(),
  indexsize = col_double()
)
# A tibble: 6 x 12
  dataset               K distance  algorithm parameters                       
  <chr>             <dbl> <chr>     <chr>     <chr>                            
1 vgg-512-euclidean    10 euclidean NGT-onng  ONNG-NGT(100, 10, 120, -2, 1.200)
2 vgg-512-euclidean    10 euclidean NGT-onng  ONNG-NGT(100, 10, 120, -2, 0.900)
3 vgg-512-euclidean    10 euclidean NGT-onng  ONNG-NGT(100, 10, 120, -2, 1.050)
4 vgg-512-euclidean    10 euclidean NGT-onng  ONNG-NGT(100, 10, 120, -2, 1.100)
5 vgg-512-euclidean    10 euclidean NGT-onng  ONNG-NGT(100, 10, 120, -2, 0.600)
6 vgg-512-euclidean    10 euclidean NGT-onng  ONNG-NGT(100, 10, 120, -2, 1.070)
  `k-nn` `accuracy-R@1` `accuracy-R@10`     qps queryTime build indexsize
   <dbl>          <dbl>           <dbl>   <dbl>     <dbl> <dbl>     <dbl>
1 1.00           0.973           0.984     39.4 0.0254    8934.  13264308
2 0.0618         0.0989          0.0995 12330.  0.0000811 8934.  13264308
3 0.571          0.560           0.566   1255.  0.000797  8934.  13264308
4 0.998          0.973           0.983    716.  0.00140   8934.  13264308
5 0.0186         0.0938          0.0941 16626.  0.0000601 8934.  13264308
6 0.908          0.890           0.898    944.  0.00106   8934.  13264308
#+end_example

#+begin_src R :results output :exports results :session 
days <- ( 2*sum(df$queryTime) * 10000 + sum(df$build))  / (3600*24)
sprintf("Total benchmark duration: %.2f days",  days)
#+end_src

#+RESULTS:
: [1] "Total benchmark duration: 15.32 days"


** Query Time vs accuracy-Rank@1

#+begin_src sh :results output none :exports none :session foo
cd ~/Projects/ann-benchmarks
python3 plot.py --dataset vgg-512-euclidean -y queryTime -x accuracy-R@1 -o reports/img/vgg-512-euclidean-query-R1.svg -Y
#+end_src

In addition to the scatter plot ( transparent points ) we also draw lines connecting points on the Pareto frontier. 
I.e. The set of optimal of runs that Minimize =Query Time= and =Maximize Accuracy=.

#+begin_src R :results output graphics :file ./img/vgg-512-euclidean-query-R1.svg :exports results :width 8 :height 5 :session 
library(rPref)

df %>% 
    filter(`accuracy-R@1` > 0.9) %>%
    group_by(algorithm) -> dff

dff %>%
    psel(high(`accuracy-R@1`) * low(queryTime)) -> df_sky

dff %>%  
    ggplot( aes(x=`accuracy-R@1`, y=queryTime*1000, color=algorithm)) +
    geom_point(alpha=0.3) +
    geom_line(data = df_sky) +
    xlim(NA,0.996) +
    labs(y = "Time (ms)") + #x = "Batch number", color="") + 
    scale_y_continuous(trans='log10')
#+end_src

#+RESULTS:
[[file:./img/vgg-512-euclidean-query-R1.svg]]

** Query Time vs accuracy-Rank@10

#+begin_src sh :results output none :exports none :session foo
cd ~/Projects/ann-benchmarks
python3 plot.py --dataset vgg-512-euclidean -y queryTime -x accuracy-R@10 -o reports/img/vgg-512-euclidean-query-R10.svg -Y
#+end_src


#+begin_src R :results output graphics :file ./img/vgg-512-euclidean-query-R10.svg :exports results :width 8 :height 5 :session 
library(rPref)

df %>% 
    filter(`accuracy-R@10` > 0.9) %>%
    group_by(algorithm) -> dff

dff %>%
    psel(high(`accuracy-R@10`) * low(queryTime)) -> df_sky

dff %>%  
    ggplot( aes(x=`accuracy-R@10`, y=queryTime*1000, color=algorithm)) +
    geom_point(alpha=0.3) +
    geom_line(data = df_sky) +
    xlim(NA,0.996) +
    labs(y = "Time (ms)") + #x = "Batch number", color="") + 
    scale_y_continuous(trans='log10')
#+end_src

#+RESULTS:
[[file:./img/vgg-512-euclidean-query-R10.svg]]

** Index Build Time vs accuracy-Rank@1

The scatter plot shows all the evaluated runs, while the lines show the optimal set of runs.

In this case, the optimal runs are selected first by taking the optimal points w.r.t =R@1 X QueryTime= and 
then selecting points to optimize =R@1 x Build Time=. 
The resulting set is shown in table bellow.

#+begin_src sh :results output none :exports none :session foo :eval never
cd ~/Projects/ann-benchmarks
python3 plot.py --dataset vgg-512-euclidean -y build -x accuracy-R@1 -o reports/img/vgg-512-euclidean-build-R1.svg -Y
#+end_src

#+begin_src R :results output graphics :file ./img/vgg-512-euclidean-build-R1.svg :exports results :width 8 :height 5 :session 
library(rPref)

df %>% 
    filter(`accuracy-R@1` > 0.9) %>%
    group_by(algorithm) -> dff

dff %>%
    psel(high(`accuracy-R@1`) * low(queryTime)) %>%
    psel(high(`accuracy-R@1`) * low(build)) -> df_sky

dff %>%  
    ggplot( aes(x=`accuracy-R@1`, y=build/60, color=algorithm)) +
    geom_point(alpha=0.3) +
    geom_line(data = df_sky) +
    xlim(NA,0.996) +
    labs(y = "Build Time (minutes)") + #x = "Batch number", color="") + 
    scale_y_continuous(trans='log10')
#+end_src

#+RESULTS:
[[file:./img/vgg-512-euclidean-build-R1.svg]]

Interesting to note that the exact method (brute-force blas) has less accuracy than other methods

The table shows all the values that have optimal Built Time and also optimal Query Time.
#+begin_src R :results table :colnames yes :exports result :session 
print(df_sky) %>% 
    mutate( query_ms = round(queryTime*1000,2), build_min = round(build/60,2), index_GB = round(indexsize/2**20,2)) %>% 
    select(parameters, query_ms, build_min, index_GB,  `accuracy-R@1`, `accuracy-R@10` ) %>% arrange(query_ms) 
#+end_src

#+RESULTS:
| algorithm        | parameters                                                                               | query_ms | build_min | index_GB | accuracy-R@1 | accuracy-R@10 |
|------------------+------------------------------------------------------------------------------------------+----------+-----------+----------+--------------+---------------|
| hnsw(nmslib)     | Nmslib(method_name=hnsw, index_param=['M=12', 'post=0', 'efConstruction=400'])           |     0.57 |    199.71 |    11.88 |       0.9601 |        0.9682 |
| hnswlib          | hnswlib ({'efConstruction': 500, 'M': 16})                                               |     1.06 |    163.93 |     5.69 |       0.9722 |        0.9818 |
| SW-graph(nmslib) | Nmslib(method_name=sw-graph, index_param=['NN=10'])                                      |     1.13 |     30.46 |     6.33 |       0.9269 |        0.9389 |
| hnswlib          | hnswlib ({'efConstruction': 500, 'M': 24})                                               |      3.5 |    254.82 |     5.85 |       0.9731 |        0.9838 |
| BallTree(nmslib) | Nmslib(method_name=vptree, index_param=['tuneK=10', 'desiredRecall=0.1'])                |     3.97 |     12.81 |    11.05 |       0.9502 |         0.965 |
| mrpt             | MRPT(target recall=0.970, trees=856, depth=13, vote threshold=3, estimated recall=0.970) |     5.36 |     72.48 |    16.22 |       0.9734 |        0.9827 |
| SW-graph(nmslib) | Nmslib(method_name=sw-graph, index_param=['NN=16'])                                      |      7.6 |     38.33 |     6.69 |       0.9703 |        0.9798 |
| faiss-ivf        | FaissIVF(n_list=4096, n_probe=5)                                                         |     7.82 |     69.18 |     7.05 |       0.9619 |        0.9712 |
| BallTree(nmslib) | Nmslib(method_name=vptree, index_param=['tuneK=10', 'desiredRecall=0.2'])                |     8.76 |     14.79 |    11.05 |       0.9594 |        0.9734 |
| SW-graph(nmslib) | Nmslib(method_name=sw-graph, index_param=['NN=24'])                                      |     9.13 |     49.22 |     7.11 |       0.9714 |        0.9818 |
| NGT-panng        | PANNG-NGT(20, 40, 60, 1.200)                                                             |    16.79 |     92.18 |     8.06 |       0.9731 |        0.9838 |
| BallTree(nmslib) | Nmslib(method_name=vptree, index_param=['tuneK=10', 'desiredRecall=0.3'])                |    17.16 |     17.45 |    11.05 |       0.9665 |        0.9796 |
| BallTree(nmslib) | Nmslib(method_name=vptree, index_param=['desiredRecall=0.4', 'tuneK=10'])                |    25.16 |     19.55 |    11.05 |       0.9683 |        0.9812 |
| NGT-onng         | ONNG-NGT(100, 10, 120, -2, 1.200)                                                        |    25.38 |     148.9 |    12.65 |       0.9731 |        0.9838 |
| BallTree(nmslib) | Nmslib(method_name=vptree, index_param=['tuneK=10', 'desiredRecall=0.5'])                |    40.64 |     20.64 |    11.05 |       0.9689 |        0.9812 |
| annoy            | Annoy(n_trees=100, search_k=100000)                                                      |    41.29 |     30.58 |     9.73 |       0.9725 |        0.9827 |
| faiss-ivf        | FaissIVF(n_list=8192, n_probe=100)                                                       |     55.4 |    245.05 |     6.95 |       0.9731 |        0.9818 |
| BallTree(nmslib) | Nmslib(method_name=vptree, index_param=['desiredRecall=0.6', 'tuneK=10'])                |    56.03 |     22.22 |    11.05 |       0.9701 |        0.9821 |
| BallTree(nmslib) | Nmslib(method_name=vptree, index_param=['desiredRecall=0.7', 'tuneK=10'])                |    75.23 |     33.63 |    11.05 |       0.9719 |        0.9835 |
| annoy            | Annoy(n_trees=200, search_k=200000)                                                      |    75.55 |     58.76 |    12.65 |       0.9731 |        0.9838 |
| BallTree(nmslib) | Nmslib(method_name=vptree, index_param=['tuneK=10', 'desiredRecall=0.8'])                |   118.19 |     34.12 |    11.05 |       0.9723 |        0.9835 |
| BallTree(nmslib) | Nmslib(method_name=vptree, index_param=['desiredRecall=0.85', 'tuneK=10'])               |   137.54 |     34.27 |    11.17 |       0.9726 |        0.9837 |
| BallTree(nmslib) | Nmslib(method_name=vptree, index_param=['desiredRecall=0.9', 'tuneK=10'])                |   170.38 |     37.13 |    11.05 |       0.9729 |         0.984 |
| BallTree(nmslib) | Nmslib(method_name=vptree, index_param=['tuneK=10', 'desiredRecall=0.95'])               |   227.92 |     37.92 |    11.05 |        0.973 |        0.9841 |
| BallTree(nmslib) | Nmslib(method_name=vptree, index_param=['desiredRecall=0.97', 'tuneK=10'])               |   267.76 |     39.59 |    11.06 |       0.9732 |         0.984 |
| bruteforce-blas  | BruteForceBLAS()                                                                         |    672.7 |      0.13 |     5.16 |        0.962 |        0.9838 |

** Index Size vs accuracy-Rank@1

#+begin_src sh :results output none :exports none :session foo
cd ~/Projects/ann-benchmarks
python3 plot.py --dataset vgg-512-euclidean -y indexsize -x accuracy-R@1 -o reports/img/vgg-512-euclidean-IndexSize-R1.svg -Y
#+end_src

Like in the previous plot we make two rounds of filtering:
- first take optimal values w.r.t =R@1 X Query Time=.
- then, take optimal values w.r.t =R@1 X Index Size=.

The following plot and table shows these optimal values only.

#+begin_src R :results output graphics :file ./img/vgg-512-euclidean-IndexSize-R1.svg :exports results :width 8 :height 5 :session 
library(rPref)

df %>% 
    filter(`accuracy-R@1` > 0.9) %>%
    group_by(algorithm) -> dff

# maximize result with according to QueryTime
dff %>%
    psel(high(`accuracy-R@1`) * low(queryTime) ) %>%
    psel(high(`accuracy-R@1`) * low(indexsize) ) -> df_sky

df_sky %>%  
    ggplot( aes(x=`accuracy-R@1`, y=indexsize/2**20, color=algorithm)) +
    geom_point(alpha=1) +
    #geom_point(data = dff, alpha=0.1) +
    xlim(NA,0.996) +
    labs(y = "IndexSize (GBytes)") + #x = "Batch number", color="") + 
    scale_y_continuous(trans='log10')
#+end_src

#+RESULTS:
[[file:./img/vgg-512-euclidean-IndexSize-R1.svg]]


#+begin_src R :results table :colnames yes :exports results :session 
print(df_sky) %>% 
    mutate( query_ms = round(queryTime*1000,2), build_min = round(build/60,2), index_GB = round(indexsize/2**20,2)) %>% 
    select(parameters, query_ms, build_min, index_GB,  `accuracy-R@1`, `accuracy-R@10` ) %>% arrange(query_ms) 
#+end_src

#+RESULTS:
| algorithm        | parameters                                                                               | query_ms | build_min | index_GB | accuracy-R@1 | accuracy-R@10 |
|------------------+------------------------------------------------------------------------------------------+----------+-----------+----------+--------------+---------------|
| hnsw(nmslib)     | Nmslib(method_name=hnsw, index_param=['M=12', 'post=0', 'efConstruction=400'])           |     0.57 |    199.71 |    11.88 |       0.9601 |        0.9682 |
| hnswlib          | hnswlib ({'efConstruction': 500, 'M': 16})                                               |     1.06 |    163.93 |     5.69 |       0.9722 |        0.9818 |
| SW-graph(nmslib) | Nmslib(method_name=sw-graph, index_param=['NN=10'])                                      |     1.13 |     30.46 |     6.33 |       0.9269 |        0.9389 |
| hnswlib          | hnswlib ({'efConstruction': 500, 'M': 24})                                               |      3.5 |    254.82 |     5.85 |       0.9731 |        0.9838 |
| mrpt             | MRPT(target recall=0.970, trees=856, depth=13, vote threshold=3, estimated recall=0.970) |     5.36 |     72.48 |    16.22 |       0.9734 |        0.9827 |
| SW-graph(nmslib) | Nmslib(method_name=sw-graph, index_param=['NN=16'])                                      |      7.6 |     38.33 |     6.69 |       0.9703 |        0.9798 |
| SW-graph(nmslib) | Nmslib(method_name=sw-graph, index_param=['NN=24'])                                      |     9.13 |     49.22 |     7.11 |       0.9714 |        0.9818 |
| NGT-panng        | PANNG-NGT(20, 40, 60, 1.200)                                                             |    16.79 |     92.18 |     8.06 |       0.9731 |        0.9838 |
| NGT-onng         | ONNG-NGT(100, 10, 120, -2, 1.200)                                                        |    25.38 |     148.9 |    12.65 |       0.9731 |        0.9838 |
| BallTree(nmslib) | Nmslib(method_name=vptree, index_param=['tuneK=10', 'desiredRecall=0.5'])                |    40.64 |     20.64 |    11.05 |       0.9689 |        0.9812 |
| annoy            | Annoy(n_trees=100, search_k=100000)                                                      |    41.29 |     30.58 |     9.73 |       0.9725 |        0.9827 |
| faiss-ivf        | FaissIVF(n_list=8192, n_probe=100)                                                       |     55.4 |    245.05 |     6.95 |       0.9731 |        0.9818 |
| BallTree(nmslib) | Nmslib(method_name=vptree, index_param=['desiredRecall=0.6', 'tuneK=10'])                |    56.03 |     22.22 |    11.05 |       0.9701 |        0.9821 |
| annoy            | Annoy(n_trees=200, search_k=200000)                                                      |    75.55 |     58.76 |    12.65 |       0.9731 |        0.9838 |
| BallTree(nmslib) | Nmslib(method_name=vptree, index_param=['tuneK=10', 'desiredRecall=0.8'])                |   118.19 |     34.12 |    11.05 |       0.9723 |        0.9835 |
| BallTree(nmslib) | Nmslib(method_name=vptree, index_param=['desiredRecall=0.9', 'tuneK=10'])                |   170.38 |     37.13 |    11.05 |       0.9729 |         0.984 |
| BallTree(nmslib) | Nmslib(method_name=vptree, index_param=['tuneK=10', 'desiredRecall=0.95'])               |   227.92 |     37.92 |    11.05 |        0.973 |        0.9841 |
| BallTree(nmslib) | Nmslib(method_name=vptree, index_param=['desiredRecall=0.97', 'tuneK=10'])               |   267.76 |     39.59 |    11.06 |       0.9732 |         0.984 |
| bruteforce-blas  | BruteForceBLAS()                                                                         |    672.7 |      0.13 |     5.16 |        0.962 |        0.9838 |










* TODO TO-DO [0/4]                                                 :noexport:

- [ ] Select algorithm to run multi-threaded
- [ ] Check which methods allow index updates
- [ ] Show knn-recall ressults
- [ ] Colocar também os dados do Recall
