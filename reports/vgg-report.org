# -*- coding: utf-8 ; org-export-babel-evaluate: t; org-confirm-babel-evaluate: nil; org-image-actual-width: 600;-*-
# -*- mode: org -*-
#+AUTHOR: Julio Toss
#+EMAIL: julio@meerkat.com.br
#+STARTUP: indent 
#+STARTUP: logdrawer hideblocks
#+OPTIONS: html-postamble:nil f:nil broken-links:mark H:5 toc:nil todo:nil ^:{}
#+PROPERTY: header-args :cache no :eval never-export
#+SEQ_TODO: TODO INPROGRESS(i) WAITING(@) | DONE NOTE DEFERRED(@) CANCELED(@)

* Content                                                               :TOC:
- [[#dataset---vgg-512-euclidean][Dataset - vgg-512-euclidean]]
- [[#evaluation-methodology][Evaluation methodology]]
  - [[#machine-configuration][Machine configuration]]
  - [[#performance-metrics][Performance Metrics]]
  - [[#quality-metrics][Quality Metrics]]
- [[#results][Results]]
  - [[#accuracy][Accuracy]]
  - [[#recall][Recall]]

* DONE Dataset - vgg-512-euclidean

Dataset from face images : https://www.robots.ox.ac.uk/~vgg/data/vgg_face2/
Face descriptors (feature vectors) were extracted with frapi's method ( arcFace )

#+begin_src python :results output table :exports results :eval never
import numpy as np
import h5py

filename = "../data/vgg-512-euclidean.hdf5"
dataset = h5py.File(filename, "r")

train = set(dataset['train_lbl'])
test = set(dataset['test_lbl'])
diff = (test - train) 

print("Vectors type:", dataset['train'].dtype)
print("Train Vectors:", dataset['train'].shape)
print("Test Vectors:", dataset['test'].shape)

print("Train Labels:", len(train))
print("Test Labels:", len(test))

print("Untrained Labels: ", len(diff))

#+end_src

#+RESULTS:
: Vectors type: float64
: Train Vectors: (2701775, 512)
: Test Vectors: (10000, 512)
: Train Labels: 8631
: Test Labels: 5748
: Untrained Labels:  0

* Evaluation methodology 

For each algorithm configuration ( algorithm + parameters ):
- we build the indexing datastructure one time.
- we perform two test /runs/. In each /run/ the full /test/ dataset is queried over the computed index.
- each query is executed individually ( no batch queries ).

Resource limits:
Each test configuration is executed in a docker container. 
Containers resources where limited to 1 CPU, unlimited memory and run timeout of 5 hours.

** Machine configuration
#+begin_src sh :session knntests :results output :exports results
#ssh knntests
echo "---- CPU ----"
lscpu
echo "---- MEM ----"
lsmem --summary
#+end_src

#+RESULTS:
#+begin_example
---- CPU ----
Architecture:        x86_64
CPU op-mode(s):      32-bit, 64-bit
Byte Order:          Little Endian
Address sizes:       46 bits physical, 48 bits virtual
CPU(s):              8
On-line CPU(s) list: 0-7
Thread(s) per core:  2
Core(s) per socket:  4
Socket(s):           1
NUMA node(s):        1
Vendor ID:           GenuineIntel
CPU family:          6
Model:               63
Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz
Stepping:            0
CPU MHz:             2300.000
BogoMIPS:            4600.00
Hypervisor vendor:   KVM
Virtualization type: full
L1d cache:           32K
L1i cache:           32K
L2 cache:            256K
L3 cache:            46080K
NUMA node0 CPU(s):   0-7
Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities
---- MEM ----
Memory block size:       128M
Total online memory:      52G
Total offline memory:      0B
#+end_example

** Performance Metrics
*** Index
- Index build time: we measure the seconds to run the method's =fit= function.
- Index memory usage: we compute the difference between the Resident Set Size , before and after the fit function.

Sample snippet: 
#+begin_src sh :results output :exports both
t0 = time.time()
memory_usage_before = algo.get_memory_usage()
algo.fit(X_train)
build_time = time.time() - t0
index_size = algo.get_memory_usage() - memory_usage_before
#+end_src

*** Query Time ( Latency )

In each test run, we measure seconds (wall time) for each query individually. 
All queries' times in a single run are added up to compute the average query time.

We perform two test /runs/ and take the best average time, which is reported in our results.

Each individual query time are save to =.hdf5= files in case we need them for extra analysis.

** Quality Metrics

The output of a knn-query is a list of neighbor's ids in the /Train/ dataset.

/Note:/ all the queries were executed on a *10-Nearest-Neighbors* index, so the response will always be a list of 10 candidates ordered by distance ( from smallest to largest ) 

From the list of candidates ids we generate a list candidate labels and compute the first position where the query label appears in the candidate list ( aka rank).

Rank computation:
#+begin_src python :results output :exports both
if query_label in neighbor_labels:
    rank_q = neighbor_labels.index( query_label )
else:
    rank_q = float(inf)
#+end_src

We computed two rank based accuracy :

- Accuracy at Rank@1 :: =( queries with rank < 1 ) / num_queries=

- Accuracy at Rank@10 :: =( queries with rank < 10) / num_queries=

Recall based on 
- Recall :: Let the results of a query $(q)$ returned by an algorithm be $X = \{ x_i | 1 <= i <= k \}$. We compute the recall as the insertction between X and the ground-truth, KNN(q): 

            $Recall = \frac{|X âˆ© kNN(q)|}{k}$
           
            We report the average recall of the test dataset.


            

* Algorithms                                                       :noexport:
** Selected algorithm 
Faiss
HNSW

* Results

#+begin_src sh :results none :exports both :eval never
# To export all the metrics to a csv.
cd ../
python3 export_to_csv.py --dataset vgg-512-euclidean
#+end_src

Raw results are available here : [[../results/vgg-512-euclidean.csv]]

#+begin_src R :results output :exports none :session 
options(crayon.enabled = FALSE)
options(dplyr.width=Inf)

library(tidyverse)
df = read_delim("../results/vgg-512-euclidean.csv", delim=',', trim_ws = TRUE )
#df %>% 
#    replace( ., . == 'ball', 'BallTree(sklearn)') %>%
#    replace( ., . == 'kd', 'KD(sklearn)') %>% 
#    replace( ., . == 'bruteforce', 'bruteforce-sk') -> df
# df %>% mutate(algorithm = replace( algorithm, algorithm == 'ball', 'BallTree(sklearn)')) %>% head()
df %>% mutate(algorithm = str_replace_all( algorithm, 
                                          c('^kd$' = 'KD(sklearn)', 
                                            '^ball$' = 'BallTree(sklearn)',
                                            '^bruteforce$' = 'brtforce(sklearn)')
                                          )) -> df

head(df)
#+end_src

#+RESULTS:
#+begin_example
Parsed with column specification:
cols(
  dataset = col_character(),
  K = col_double(),
  distance = col_character(),
  algorithm = col_character(),
  parameters = col_character(),
  `knn-dist` = col_double(),
  `knn-set` = col_double(),
  `accuracy-R@1` = col_double(),
  `accuracy-R@10` = col_double(),
  qps = col_double(),
  queryTime = col_double(),
  build = col_double(),
  indexsize = col_double()
)
# A tibble: 6 x 13
  dataset               K distance  algorithm        
  <chr>             <dbl> <chr>     <chr>            
1 vgg-512-euclidean    10 euclidean KD(sklearn)      
2 vgg-512-euclidean    10 euclidean brtforce(sklearn)
3 vgg-512-euclidean    10 euclidean NGT-onng         
4 vgg-512-euclidean    10 euclidean NGT-onng         
5 vgg-512-euclidean    10 euclidean NGT-onng         
6 vgg-512-euclidean    10 euclidean NGT-onng         
  parameters                        `knn-dist` `knn-set` `accuracy-R@1`
  <chr>                                  <dbl>     <dbl>          <dbl>
1 KDTree(leaf_size=30)                  1         1              0.977 
2 BruteForce()                          1         1              0.979 
3 ONNG-NGT(100, 10, 120, -2, 1.200)     1.00      1.00           0.973 
4 ONNG-NGT(100, 10, 120, -2, 0.900)     0.0618    0.0609         0.0989
5 ONNG-NGT(100, 10, 120, -2, 1.050)     0.571     0.569          0.560 
6 ONNG-NGT(100, 10, 120, -2, 1.100)     0.998     0.997          0.973 
  `accuracy-R@10`       qps queryTime   build indexsize
            <dbl>     <dbl>     <dbl>   <dbl>     <dbl>
1          0.984      0.262 3.82       539.     1073868
2          0.985      0.303 3.30         1.11         0
3          0.984     39.4   0.0254    8934.    13264308
4          0.0995 12330.    0.0000811 8934.    13264308
5          0.566   1255.    0.000797  8934.    13264308
6          0.983    716.    0.00140   8934.    13264308
#+end_example

#+begin_src R :results output :exports results :session 
days <- ( 2*sum(df$queryTime) * 10000 + sum(df$build))  / (3600*24)
sprintf("Total benchmark duration: %.2f days",  days)
#+end_src

#+RESULTS:
: [1] "Total benchmark duration: 21.48 days"

** Accuracy 
*** Query Time vs accuracy-Rank@1

In addition to the scatter plot ( transparent points ) we also draw lines connecting points on the Pareto frontier. 
I.e. the set of optimal of runs that Minimize =Query Time= and =Maximize Accuracy=.

#+begin_src R :results output graphics :file ./img/vgg-512-euclidean-query-R1.svg :exports results :width 8 :height 5 :session 
library(rPref)
library(ggrepel)

df %>% 
    filter(`accuracy-R@1` > 0.9) %>%
    group_by(algorithm) -> dff

dff %>%
    psel(high(`accuracy-R@1`) * low(queryTime)) -> df_sky

df_sky %>%  
    ggplot( aes(x=`accuracy-R@1`, y=queryTime*1000, color=algorithm)) +
    geom_point(data = dff, alpha=0.3) +
    geom_line() +
    geom_label_repel( 
        data=df_sky %>%  filter(`accuracy-R@1` == max(`accuracy-R@1`)),
        aes(label=algorithm) ,
        box.padding   = 0.35, 
        point.padding = 0.5
    )+
    xlim(NA,0.996) +
    labs(y = "Time (ms)") + #x = "Batch number", color="") + 
    scale_y_continuous(trans='log10') +
    theme(legend.position="none")

#+end_src

#+RESULTS:
[[file:./img/vgg-512-euclidean-query-R1.svg]]

TO-DO:
- [ ] Check why we have different results for bruteforce-blas / brtforce(sklearn) 

*** Query Time vs accuracy-Rank@10


#+begin_src R :results output graphics :file ./img/vgg-512-euclidean-query-R10.svg :exports results :width 8 :height 5 :session 
library(rPref)
library(ggrepel)

df %>% 
    filter(`accuracy-R@10` > 0.9) %>%
    group_by(algorithm) -> dff

dff %>%
    psel(high(`accuracy-R@10`) * low(queryTime)) -> df_sky

df_sky %>%  
    ggplot( aes(x=`accuracy-R@10`, y=queryTime*1000, color=algorithm)) +
    geom_point(data = dff, alpha=0.3) +
    geom_line() +
    geom_label_repel( 
        data=df_sky %>%  filter(`accuracy-R@10` == max(`accuracy-R@10`)),
        aes(label=algorithm) ,
        box.padding   = 0.35, 
        point.padding = 0.5
    )+
    xlim(NA,0.996) +
    labs(y = "Time (ms)") + #x = "Batch number", color="") + 
    scale_y_continuous(trans='log10') +
    theme(legend.position="none")
#+end_src

#+RESULTS:
[[file:./img/vgg-512-euclidean-query-R10.svg]]

*** Index Build Time vs accuracy-Rank@1

The scatter plot shows all the evaluated runs, while the lines show the optimal set of runs.

+In this case, the optimal runs are selected first by taking the optimal points w.r.t =R@1 X QueryTime= and+
Showing pareto set of points optimizing =R@1 x Build Time=. 
The resulting set is shown in table bellow.

#+begin_src sh :results output none :exports none :session foo :eval never
cd ~/Projects/ann-benchmarks
python3 plot.py --dataset vgg-512-euclidean -y build -x accuracy-R@1 -o reports/img/vgg-512-euclidean-build-R1.svg -Y
#+end_src

#+begin_src R :results output graphics :file ./img/vgg-512-euclidean-build-R1.svg :exports results :width 8 :height 5 :session 
library(rPref)

df %>% 
    filter(`accuracy-R@1` > 0.9) %>%
    group_by(algorithm) -> dff

dff %>%
 #   psel(high(`accuracy-R@1`) * low(queryTime)) %>%
    psel(high(`accuracy-R@1`) * low(build)) -> df_sky

df_sky %>%  
    ggplot( aes(x=`accuracy-R@1`, y=build/60, color=algorithm)) +
    geom_point(alpha=0.3) +
    geom_line() +
    geom_label_repel( 
        data=df_sky %>%  filter(`accuracy-R@1` == max(`accuracy-R@1`)),
        aes(label=algorithm) ,
        box.padding   = 0.35, 
        point.padding = 0.5
    )+
    xlim(NA,0.996) +
    labs(y = "Build Time (minutes)") + #x = "Batch number", color="") + 
    scale_y_continuous(trans='log10') + 
theme(legend.position="none")
#+end_src

#+RESULTS:
[[file:./img/vgg-512-euclidean-build-R1.svg]]

Interesting to note that the exact method (brute-force blas) has less accuracy than other methods

The table shows all the values that have optimal Built Time and also optimal Query Time.
#+begin_src R :results table :colnames yes :exports result :session 
print(df_sky) %>% 
    mutate( query_ms = round(queryTime*1000,2), 
           build_min = round(build/60,2), 
           index_GB = round(indexsize/2**20,2),
           `accuracy-R@1` = round(`accuracy-R@1`, 3), 
           `accuracy-R@10` = round(`accuracy-R@10`, 3)
           ) %>% 
    select(parameters, query_ms, build_min, index_GB,  `accuracy-R@1`, `accuracy-R@10` ) %>% arrange(query_ms) 
#+end_src

#+RESULTS:
| algorithm         | parameters                                                                               | query_ms | build_min | index_GB | accuracy-R@1 | accuracy-R@10 |
|-------------------+------------------------------------------------------------------------------------------+----------+-----------+----------+--------------+---------------|
| hnsw(nmslib)      | Nmslib(method_name=hnsw, index_param=['M=8', 'efConstruction=400', 'post=0'])            |     0.52 |    134.85 |    11.65 |        0.927 |         0.935 |
| hnsw(nmslib)      | Nmslib(method_name=hnsw, index_param=['M=12', 'post=0', 'efConstruction=400'])           |     0.57 |    199.71 |    11.88 |         0.96 |         0.968 |
| hnswlib           | hnswlib ({'M': 4, 'efConstruction': 500})                                                |     1.42 |     65.88 |     5.46 |        0.954 |         0.962 |
| hnswlib           | hnswlib ({'efConstruction': 500, 'M': 8})                                                |     2.64 |     97.67 |     5.53 |        0.972 |         0.983 |
| hnswlib           | hnswlib ({'efConstruction': 500, 'M': 12})                                               |     3.77 |    135.13 |     5.61 |        0.973 |         0.984 |
| BallTree(nmslib)  | Nmslib(method_name=vptree, index_param=['tuneK=10', 'desiredRecall=0.1'])                |     3.97 |     12.81 |    11.05 |         0.95 |         0.965 |
| hnswlib           | hnswlib ({'efConstruction': 500, 'M': 16})                                               |     4.69 |    163.93 |     5.69 |        0.973 |         0.984 |
| mrpt              | MRPT(target recall=0.970, trees=856, depth=13, vote threshold=3, estimated recall=0.970) |     5.36 |     72.48 |    16.22 |        0.973 |         0.983 |
| SW-graph(nmslib)  | Nmslib(method_name=sw-graph, index_param=['NN=10'])                                      |     6.01 |     30.46 |     6.33 |        0.967 |         0.977 |
| SW-graph(nmslib)  | Nmslib(method_name=sw-graph, index_param=['NN=16'])                                      |      7.6 |     38.33 |     6.69 |         0.97 |          0.98 |
| BallTree(nmslib)  | Nmslib(method_name=vptree, index_param=['tuneK=10', 'desiredRecall=0.2'])                |     8.76 |     14.79 |    11.05 |        0.959 |         0.973 |
| SW-graph(nmslib)  | Nmslib(method_name=sw-graph, index_param=['NN=24'])                                      |     9.13 |     49.22 |     7.11 |        0.971 |         0.982 |
| NGT-panng         | PANNG-NGT(20, 40, 60, 1.200)                                                             |    16.79 |     92.18 |     8.06 |        0.973 |         0.984 |
| BallTree(nmslib)  | Nmslib(method_name=vptree, index_param=['tuneK=10', 'desiredRecall=0.3'])                |    17.16 |     17.45 |    11.05 |        0.967 |          0.98 |
| BallTree(nmslib)  | Nmslib(method_name=vptree, index_param=['desiredRecall=0.4', 'tuneK=10'])                |    25.16 |     19.55 |    11.05 |        0.968 |         0.981 |
| NGT-onng          | ONNG-NGT(100, 10, 120, -2, 1.200)                                                        |    25.38 |     148.9 |    12.65 |        0.973 |         0.984 |
| faiss-lsh         | FaissLSH(n_bits=256)                                                                     |    38.36 |      0.52 |     0.26 |        0.952 |         0.974 |
| BallTree(nmslib)  | Nmslib(method_name=vptree, index_param=['tuneK=10', 'desiredRecall=0.5'])                |    40.64 |     20.64 |    11.05 |        0.969 |         0.981 |
| BallTree(nmslib)  | Nmslib(method_name=vptree, index_param=['desiredRecall=0.6', 'tuneK=10'])                |    56.03 |     22.22 |    11.05 |         0.97 |         0.982 |
| BallTree(nmslib)  | Nmslib(method_name=vptree, index_param=['desiredRecall=0.7', 'tuneK=10'])                |    75.23 |     33.63 |    11.05 |        0.972 |         0.984 |
| annoy             | Annoy(n_trees=200, search_k=200000)                                                      |    75.55 |     58.76 |    12.65 |        0.973 |         0.984 |
| faiss-lsh         | FaissLSH(n_bits=512)                                                                     |   113.11 |      0.88 |     0.35 |        0.966 |          0.98 |
| BallTree(nmslib)  | Nmslib(method_name=vptree, index_param=['tuneK=10', 'desiredRecall=0.8'])                |   118.19 |     34.12 |    11.05 |        0.972 |         0.984 |
| BallTree(nmslib)  | Nmslib(method_name=vptree, index_param=['desiredRecall=0.85', 'tuneK=10'])               |   137.54 |     34.27 |    11.17 |        0.973 |         0.984 |
| annoy             | Annoy(n_trees=100, search_k=400000)                                                      |   141.04 |     30.58 |     9.73 |        0.973 |         0.984 |
| faiss-lsh         | FaissLSH(n_bits=1024)                                                                    |   207.49 |      1.87 |     0.54 |         0.97 |         0.982 |
| BallTree(nmslib)  | Nmslib(method_name=vptree, index_param=['tuneK=10', 'desiredRecall=0.99'])               |   361.13 |     35.36 |    11.05 |        0.973 |         0.984 |
| faiss-lsh         | FaissLSH(n_bits=2048)                                                                    |   428.43 |      3.67 |     0.85 |        0.972 |         0.984 |
| bruteforce-blas   | BruteForceBLAS()                                                                         |    672.7 |      0.13 |     5.16 |        0.962 |         0.984 |
| faiss-ivf         | FaissIVF(n_list=32, n_probe=100)                                                         |  1933.19 |      0.66 |      5.4 |        0.974 |         0.985 |
| BallTree(sklearn) | BallTree(leaf_size=30)                                                                   |   3057.8 |      9.48 |     0.52 |        0.979 |         0.985 |
| brtforce(sklearn) | BruteForce()                                                                             |  3304.93 |      0.02 |        0 |        0.979 |         0.985 |
| KD(sklearn)       | KDTree(leaf_size=30)                                                                     |  3815.62 |      8.98 |     1.02 |        0.977 |         0.984 |

*** Index Size vs accuracy-Rank@1

#+begin_src sh :results output none :exports none :session foo :eval never
cd ~/Projects/ann-benchmarks
python3 plot.py --dataset vgg-512-euclidean -y indexsize -x accuracy-R@1 -o reports/img/vgg-512-euclidean-IndexSize-R1.svg -Y
#+end_src

Like in the previous plot we only show the pareto-optimal set of points with high =R@1= and low =Index Size=

#+begin_src R :results output graphics :file ./img/vgg-512-euclidean-IndexSize-R1.svg :exports results :width 8 :height 5 :session 
library(rPref)

df %>% 
    filter(`accuracy-R@1` > 0.9) %>%
    group_by(algorithm) -> dff

# maximize result with according to QueryTime
dff %>%
    psel(high(`accuracy-R@1`) * low(indexsize) ) -> df_sky

df_sky %>%  
    ggplot( aes(x=`accuracy-R@1`, y=indexsize/2**20, color=algorithm)) +
    geom_point(alpha=1) +
    geom_line() +
    geom_label_repel( 
        data=df_sky %>%  filter(`knn-set` == max(`knn-set`)),
        aes(label=algorithm) ,
        box.padding   = 0.35, 
        point.padding = 0.5
    )+
    xlim(NA,0.996) +
    labs(y = "IndexSize (GBytes)") + #x = "Batch number", color="") + 
    scale_y_continuous(trans='log10') +
theme(legend.position="none")

#+end_src

#+RESULTS:
[[file:./img/vgg-512-euclidean-IndexSize-R1.svg]]


#+begin_src R :results table :colnames yes :exports results :session 
print(df_sky) %>% 
    mutate( query_ms = round(queryTime*1000,2), 
           build_min = round(build/60,2), 
           index_GB = round(indexsize/2**20,2), 
           `accuracy-R@1`=round(`accuracy-R@1`,3), 
           `accuracy-R@10`=round(`accuracy-R@10`,3) ) %>% 
    select(parameters, query_ms, build_min, index_GB,  `accuracy-R@1`, `accuracy-R@10` ) %>% arrange(query_ms) 
#+end_src

#+RESULTS:
| algorithm         | parameters                                                                               | query_ms | build_min | index_GB | accuracy-R@1 | accuracy-R@10 |
|-------------------+------------------------------------------------------------------------------------------+----------+-----------+----------+--------------+---------------|
| hnsw(nmslib)      | Nmslib(method_name=hnsw, index_param=['M=8', 'efConstruction=400', 'post=0'])            |     0.52 |    134.85 |    11.65 |        0.927 |         0.935 |
| hnsw(nmslib)      | Nmslib(method_name=hnsw, index_param=['M=12', 'post=0', 'efConstruction=400'])           |     0.57 |    199.71 |    11.88 |         0.96 |         0.968 |
| hnswlib           | hnswlib ({'M': 4, 'efConstruction': 500})                                                |     1.42 |     65.88 |     5.46 |        0.954 |         0.962 |
| hnswlib           | hnswlib ({'efConstruction': 500, 'M': 8})                                                |     2.64 |     97.67 |     5.53 |        0.972 |         0.983 |
| hnswlib           | hnswlib ({'efConstruction': 500, 'M': 12})                                               |     3.77 |    135.13 |     5.61 |        0.973 |         0.984 |
| hnswlib           | hnswlib ({'efConstruction': 500, 'M': 16})                                               |     4.69 |    163.93 |     5.69 |        0.973 |         0.984 |
| mrpt              | MRPT(target recall=0.970, trees=856, depth=13, vote threshold=3, estimated recall=0.970) |     5.36 |     72.48 |    16.22 |        0.973 |         0.983 |
| SW-graph(nmslib)  | Nmslib(method_name=sw-graph, index_param=['NN=10'])                                      |     6.01 |     30.46 |     6.33 |        0.967 |         0.977 |
| SW-graph(nmslib)  | Nmslib(method_name=sw-graph, index_param=['NN=16'])                                      |      7.6 |     38.33 |     6.69 |         0.97 |          0.98 |
| SW-graph(nmslib)  | Nmslib(method_name=sw-graph, index_param=['NN=24'])                                      |     9.13 |     49.22 |     7.11 |        0.971 |         0.982 |
| NGT-panng         | PANNG-NGT(20, 40, 60, 1.200)                                                             |    16.79 |     92.18 |     8.06 |        0.973 |         0.984 |
| NGT-onng          | ONNG-NGT(100, 10, 120, -2, 1.200)                                                        |    25.38 |     148.9 |    12.65 |        0.973 |         0.984 |
| faiss-lsh         | FaissLSH(n_bits=256)                                                                     |    38.36 |      0.52 |     0.26 |        0.952 |         0.974 |
| BallTree(nmslib)  | Nmslib(method_name=vptree, index_param=['tuneK=10', 'desiredRecall=0.5'])                |    40.64 |     20.64 |    11.05 |        0.969 |         0.981 |
| annoy             | Annoy(n_trees=200, search_k=200000)                                                      |    75.55 |     58.76 |    12.65 |        0.973 |         0.984 |
| faiss-lsh         | FaissLSH(n_bits=512)                                                                     |   113.11 |      0.88 |     0.35 |        0.966 |          0.98 |
| annoy             | Annoy(n_trees=100, search_k=400000)                                                      |   141.04 |     30.58 |     9.73 |        0.973 |         0.984 |
| faiss-lsh         | FaissLSH(n_bits=1024)                                                                    |   207.49 |      1.87 |     0.54 |         0.97 |         0.982 |
| BallTree(nmslib)  | Nmslib(method_name=vptree, index_param=['tuneK=10', 'desiredRecall=0.99'])               |   361.13 |     35.36 |    11.05 |        0.973 |         0.984 |
| faiss-lsh         | FaissLSH(n_bits=2048)                                                                    |   428.43 |      3.67 |     0.85 |        0.972 |         0.984 |
| bruteforce-blas   | BruteForceBLAS()                                                                         |    672.7 |      0.13 |     5.16 |        0.962 |         0.984 |
| faiss-ivf         | FaissIVF(n_list=32, n_probe=50)                                                          |  1931.64 |      0.67 |     5.33 |        0.973 |         0.984 |
| faiss-ivf         | FaissIVF(n_list=32, n_probe=100)                                                         |  1933.19 |      0.66 |      5.4 |        0.974 |         0.985 |
| BallTree(sklearn) | BallTree(leaf_size=30)                                                                   |   3057.8 |      9.48 |     0.52 |        0.979 |         0.985 |
| brtforce(sklearn) | BruteForce()                                                                             |  3304.93 |      0.02 |        0 |        0.979 |         0.985 |
| KD(sklearn)       | KDTree(leaf_size=30)                                                                     |  3815.62 |      8.98 |     1.02 |        0.977 |         0.984 |










** Recall 

*** Query Time vs Recall

#+begin_src R :results output graphics :file ./img/vgg-512-euclidean-query-knn-set.svg :exports results :width 8 :height 5 :session 
library(rPref)

df %>% 
    filter(`knn-set` > 0.9) %>%
    replace( ., . == 'ball', 'BallTree(sklearn)') %>%
    replace( ., . == 'kd', 'KD(sklearn)') %>% 
    replace( ., . == 'bruteforce', 'bruteforce-sk') %>% 
    group_by(algorithm) -> dff

dff %>%
    psel(high(`knn-set`) * low(queryTime)) -> df_sky

dff %>%  
    ggplot( aes(x=`knn-set`, y=queryTime*1000, color=algorithm)) +
    geom_point(alpha=0.3) +
    geom_line(data = df_sky) +
    geom_label_repel( 
        data=df_sky %>%  filter(`knn-set` == max(`knn-set`)),
        aes(label=algorithm) ,
        box.padding   = 0.35, 
        point.padding = 0.5
    )+
    labs(y = "Time (ms)") + #x = "Batch number", color="") + 
    scale_y_continuous(trans='log10') +
theme(legend.position="none")

#+end_src

#+RESULTS:
[[file:./img/vgg-512-euclidean-query-knn-set.svg]]


*** Index Build Time vs Recall

#+begin_src R :results output graphics :file ./img/vgg-512-euclidean-build-knn-set.svg :exports results :width 8 :height 5 :session 

library(rPref)
library(ggrepel)

df %>% 
    filter(`knn-set` > 0.4) %>%
    group_by(algorithm) -> dff

dff %>%
    #psel(high(`knn-set`) * low(queryTime)) %>%
    psel(high(`knn-set`) * low(build)) -> df_sky

df_sky %>%  
    ggplot( aes(x=`knn-set`, y=build/60,  color=algorithm)) +
    geom_point() +
    geom_line() +
    geom_label_repel( 
        data=df_sky %>%  filter(`knn-set` == min(`knn-set`)),
        aes(label=algorithm) ,
        box.padding   = 0.35, 
        point.padding = 0.5
    )+
    labs(y = "Build Time (minutes)") + #x = "Batch number", color="") + 
    scale_y_continuous(trans='log10')+
theme(legend.position="none")
#+end_src

#+RESULTS:
[[file:./img/vgg-512-euclidean-build-knn-set.svg]]


#+begin_src R :results table :colnames yes :exports result :session 
print(df_sky) %>% 
    mutate( `knn-set` = round(`knn-set`, 4), query_ms = round(queryTime*1000,2), build_min = round(build/60,2), index_GB = round(indexsize/2**20,2)) %>% 
    select(parameters, `knn-set`, build_min, query_ms , index_GB,   ) %>% arrange(build_min) 
#+end_src

#+RESULTS:
| algorithm         | parameters                                                                               | knn-set | build_min | query_ms | index_GB |
|-------------------+------------------------------------------------------------------------------------------+---------+-----------+----------+----------|
| brtforce(sklearn) | BruteForce()                                                                             |       1 |      0.02 |  3304.93 |        0 |
| bruteforce-blas   | BruteForceBLAS()                                                                         |  0.9999 |      0.13 |    672.7 |     5.16 |
| faiss-lsh         | FaissLSH(n_bits=256)                                                                     |  0.4474 |      0.52 |    38.36 |     0.26 |
| faiss-ivf         | FaissIVF(n_list=32, n_probe=100)                                                         |  0.9999 |      0.66 |  1933.19 |      5.4 |
| faiss-ivf         | FaissIVF(n_list=32, n_probe=50)                                                          |  0.9999 |      0.67 |  1931.64 |     5.33 |
| faiss-lsh         | FaissLSH(n_bits=512)                                                                     |  0.5835 |      0.88 |   113.11 |     0.35 |
| faiss-lsh         | FaissLSH(n_bits=1024)                                                                    |  0.6837 |      1.87 |   207.49 |     0.54 |
| faiss-lsh         | FaissLSH(n_bits=2048)                                                                    |  0.7642 |      3.67 |   428.43 |     0.85 |
| KD(sklearn)       | KDTree(leaf_size=30)                                                                     |       1 |      8.98 |  3815.62 |     1.02 |
| BallTree(sklearn) | BallTree(leaf_size=30)                                                                   |       1 |      9.48 |   3057.8 |     0.52 |
| BallTree(nmslib)  | Nmslib(method_name=vptree, index_param=['tuneK=10', 'desiredRecall=0.3'])                |  0.4897 |     17.45 |    17.16 |    11.05 |
| BallTree(nmslib)  | Nmslib(method_name=vptree, index_param=['desiredRecall=0.4', 'tuneK=10'])                |  0.5669 |     19.55 |    25.16 |    11.05 |
| BallTree(nmslib)  | Nmslib(method_name=vptree, index_param=['tuneK=10', 'desiredRecall=0.5'])                |   0.648 |     20.64 |    40.64 |    11.05 |
| BallTree(nmslib)  | Nmslib(method_name=vptree, index_param=['desiredRecall=0.6', 'tuneK=10'])                |  0.7236 |     22.22 |    56.03 |    11.05 |
| SW-graph(nmslib)  | Nmslib(method_name=sw-graph, index_param=['NN=10'])                                      |  0.7665 |     30.46 |     6.01 |     6.33 |
| annoy             | Annoy(n_trees=100, search_k=400000)                                                      |  0.9966 |     30.58 |   141.04 |     9.73 |
| BallTree(nmslib)  | Nmslib(method_name=vptree, index_param=['desiredRecall=0.7', 'tuneK=10'])                |  0.7867 |     33.63 |    75.23 |    11.05 |
| BallTree(nmslib)  | Nmslib(method_name=vptree, index_param=['tuneK=10', 'desiredRecall=0.8'])                |  0.8626 |     34.12 |   118.19 |    11.05 |
| BallTree(nmslib)  | Nmslib(method_name=vptree, index_param=['desiredRecall=0.85', 'tuneK=10'])               |  0.8949 |     34.27 |   137.54 |    11.17 |
| BallTree(nmslib)  | Nmslib(method_name=vptree, index_param=['tuneK=10', 'desiredRecall=0.99'])               |  0.9911 |     35.36 |   361.13 |    11.05 |
| SW-graph(nmslib)  | Nmslib(method_name=sw-graph, index_param=['NN=16'])                                      |  0.9006 |     38.33 |      7.6 |     6.69 |
| SW-graph(nmslib)  | Nmslib(method_name=sw-graph, index_param=['NN=24'])                                      |  0.9568 |     49.22 |     9.13 |     7.11 |
| annoy             | Annoy(n_trees=200, search_k=400000)                                                      |  0.9979 |     58.76 |   139.57 |    12.65 |
| hnswlib           | hnswlib ({'M': 4, 'efConstruction': 500})                                                |  0.9444 |     65.88 |     1.42 |     5.46 |
| mrpt              | MRPT(target recall=0.995, trees=900, depth=11, vote threshold=4, estimated recall=0.995) |  0.9929 |     72.48 |    15.92 |    16.22 |
| hnsw(nmslib)      | Nmslib(method_name=hnsw, index_param=['efConstruction=400', 'M=4', 'post=0'])            |  0.5692 |      88.6 |     0.34 |    11.43 |
| NGT-panng         | PANNG-NGT(20, 40, 60, 1.200)                                                             |  0.9984 |     92.18 |    16.79 |     8.06 |
| hnswlib           | hnswlib ({'efConstruction': 500, 'M': 8})                                                |  0.9953 |     97.67 |     2.64 |     5.53 |
| annoy             | Annoy(n_trees=400, search_k=400000)                                                      |  0.9987 |     115.3 |   138.26 |    21.39 |
| hnsw(nmslib)      | Nmslib(method_name=hnsw, index_param=['M=8', 'efConstruction=400', 'post=0'])            |  0.9368 |    134.85 |     0.52 |    11.65 |
| hnswlib           | hnswlib ({'efConstruction': 500, 'M': 12})                                               |  0.9979 |    135.13 |     3.77 |     5.61 |
| NGT-onng          | ONNG-NGT(100, 10, 120, -2, 1.200)                                                        |  0.9998 |     148.9 |    25.38 |    12.65 |
| hnswlib           | hnswlib ({'efConstruction': 500, 'M': 16})                                               |  0.9987 |    163.93 |     4.69 |     5.69 |
| hnsw(nmslib)      | Nmslib(method_name=hnsw, index_param=['M=12', 'post=0', 'efConstruction=400'])           |  0.9761 |    199.71 |     0.57 |    11.88 |
| hnswlib           | hnswlib ({'efConstruction': 500, 'M': 24})                                               |  0.9992 |    254.82 |     7.57 |     5.85 |


*** Index Size vs Recall


#+begin_src R :results output graphics :file ./img/vgg-512-euclidean-IndexSize-knn-set.svg :exports results :width 8 :height 5 :session 

library(rPref)
library(ggrepel)

df %>% 
    filter(`knn-set` > 0.4) %>%
    replace( ., . == 'ball', 'BallTree(sklearn)') %>%
    replace( ., . == 'kd', 'KD(sklearn)') %>% 
    replace( ., . == 'bruteforce', 'bruteforce-sk') %>% 
    group_by(algorithm) -> dff

dff %>%
    psel(high(`knn-set`) * low(indexsize)) -> df_sky

df_sky %>%  
    ggplot( aes(x=`knn-set`, y=indexsize/2**20,  color=algorithm)) +
    geom_point() +
    geom_line() +
    geom_label_repel( 
        data=df_sky %>%  filter(`knn-set` == min(`knn-set`)),
        aes(label=algorithm) ,
        box.padding   = 0.35, 
        point.padding = 0.5
    )+
    labs(y = "IndexSize (GBytes)") + #x = "Batch number", color="") + 
    scale_y_continuous(trans='log10')+
theme(legend.position="none")
#+end_src

#+RESULTS:
[[file:./img/vgg-512-euclidean-IndexSize-knn-set.svg]]


#+begin_src R :results table :colnames yes :exports results :session 
print(df_sky) %>% 
    mutate( `knn-set` = round(`knn-set`, 4),  query_ms = round(queryTime*1000,2), build_min = round(build/60,2), index_GB = round(indexsize/2**20,2)) %>% 
    select(parameters, `knn-set`, query_ms, build_min, index_GB ) %>% arrange(index_GB) 
#+end_src

#+RESULTS:
| algorithm         | parameters                                                                               | knn-set | query_ms | build_min | index_GB |
|-------------------+------------------------------------------------------------------------------------------+---------+----------+-----------+----------|
| brtforce(sklearn) | BruteForce()                                                                             |       1 |  3304.93 |      0.02 |        0 |
| faiss-lsh         | FaissLSH(n_bits=256)                                                                     |  0.4474 |    38.36 |      0.52 |     0.26 |
| faiss-lsh         | FaissLSH(n_bits=512)                                                                     |  0.5835 |   113.11 |      0.88 |     0.35 |
| BallTree(sklearn) | BallTree(leaf_size=30)                                                                   |       1 |   3057.8 |      9.48 |     0.52 |
| faiss-lsh         | FaissLSH(n_bits=1024)                                                                    |  0.6837 |   207.49 |      1.87 |     0.54 |
| faiss-lsh         | FaissLSH(n_bits=2048)                                                                    |  0.7642 |   428.43 |      3.67 |     0.85 |
| KD(sklearn)       | KDTree(leaf_size=30)                                                                     |       1 |  3815.62 |      8.98 |     1.02 |
| bruteforce-blas   | BruteForceBLAS()                                                                         |  0.9999 |    672.7 |      0.13 |     5.16 |
| faiss-ivf         | FaissIVF(n_list=32, n_probe=50)                                                          |  0.9999 |  1931.64 |      0.67 |     5.33 |
| hnswlib           | hnswlib ({'M': 4, 'efConstruction': 500})                                                |  0.9444 |     1.42 |     65.88 |     5.46 |
| hnswlib           | hnswlib ({'efConstruction': 500, 'M': 8})                                                |  0.9953 |     2.64 |     97.67 |     5.53 |
| hnswlib           | hnswlib ({'efConstruction': 500, 'M': 12})                                               |  0.9979 |     3.77 |    135.13 |     5.61 |
| hnswlib           | hnswlib ({'efConstruction': 500, 'M': 16})                                               |  0.9987 |     4.69 |    163.93 |     5.69 |
| hnswlib           | hnswlib ({'efConstruction': 500, 'M': 24})                                               |  0.9992 |     7.57 |    254.82 |     5.85 |
| SW-graph(nmslib)  | Nmslib(method_name=sw-graph, index_param=['NN=10'])                                      |  0.7665 |     6.01 |     30.46 |     6.33 |
| SW-graph(nmslib)  | Nmslib(method_name=sw-graph, index_param=['NN=16'])                                      |  0.9006 |      7.6 |     38.33 |     6.69 |
| SW-graph(nmslib)  | Nmslib(method_name=sw-graph, index_param=['NN=24'])                                      |  0.9568 |     9.13 |     49.22 |     7.11 |
| NGT-panng         | PANNG-NGT(20, 40, 60, 1.200)                                                             |  0.9984 |    16.79 |     92.18 |     8.06 |
| annoy             | Annoy(n_trees=100, search_k=400000)                                                      |  0.9966 |   141.04 |     30.58 |     9.73 |
| BallTree(nmslib)  | Nmslib(method_name=vptree, index_param=['tuneK=10', 'desiredRecall=0.5'])                |   0.648 |    40.64 |     20.64 |    11.05 |
| BallTree(nmslib)  | Nmslib(method_name=vptree, index_param=['tuneK=10', 'desiredRecall=0.99'])               |  0.9911 |   361.13 |     35.36 |    11.05 |
| hnsw(nmslib)      | Nmslib(method_name=hnsw, index_param=['efConstruction=400', 'M=4', 'post=0'])            |  0.5692 |     0.34 |      88.6 |    11.43 |
| hnsw(nmslib)      | Nmslib(method_name=hnsw, index_param=['M=8', 'efConstruction=400', 'post=0'])            |  0.9368 |     0.52 |    134.85 |    11.65 |
| hnsw(nmslib)      | Nmslib(method_name=hnsw, index_param=['M=12', 'post=0', 'efConstruction=400'])           |  0.9761 |     0.57 |    199.71 |    11.88 |
| annoy             | Annoy(n_trees=200, search_k=400000)                                                      |  0.9979 |   139.57 |     58.76 |    12.65 |
| NGT-onng          | ONNG-NGT(100, 10, 120, -2, 1.200)                                                        |  0.9998 |    25.38 |     148.9 |    12.65 |
| mrpt              | MRPT(target recall=0.995, trees=900, depth=11, vote threshold=4, estimated recall=0.995) |  0.9929 |    15.92 |     72.48 |    16.22 |
| annoy             | Annoy(n_trees=400, search_k=400000)                                                      |  0.9987 |   138.26 |     115.3 |    21.39 |









* TODO TO-DO [1/5]                                                 :noexport:

- [ ] Test dataset size scaling
- [ ] Test multi-threaded performance on selected algorithms
- [ ] Test other algorithms:
  - [ ] FAISS with quantization
- [ ] Check which methods allow index updates
- [X] Show knn-set recall in results
